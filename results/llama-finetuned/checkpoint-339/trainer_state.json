{
  "best_global_step": 200,
  "best_metric": 2.0029239654541016,
  "best_model_checkpoint": "./results/llama-finetuned\\checkpoint-200",
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 339,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 3.361659288406372,
      "learning_rate": 1.8e-05,
      "loss": 3.8613,
      "step": 10
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 3.3028271198272705,
      "learning_rate": 3.8e-05,
      "loss": 3.7799,
      "step": 20
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 5.705636501312256,
      "learning_rate": 5.8e-05,
      "loss": 3.0732,
      "step": 30
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 2.6411588191986084,
      "learning_rate": 7.800000000000001e-05,
      "loss": 2.525,
      "step": 40
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 2.230851650238037,
      "learning_rate": 9.8e-05,
      "loss": 2.4294,
      "step": 50
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 2.9221889972686768,
      "learning_rate": 0.000118,
      "loss": 2.354,
      "step": 60
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 2.1439480781555176,
      "learning_rate": 0.000138,
      "loss": 2.1385,
      "step": 70
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 1.7350246906280518,
      "learning_rate": 0.00015800000000000002,
      "loss": 2.146,
      "step": 80
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8650704622268677,
      "learning_rate": 0.00017800000000000002,
      "loss": 2.1455,
      "step": 90
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 4.0972161293029785,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.0598,
      "step": 100
    },
    {
      "epoch": 0.8888888888888888,
      "eval_loss": 2.173072576522827,
      "eval_runtime": 13.8715,
      "eval_samples_per_second": 7.209,
      "eval_steps_per_second": 3.605,
      "step": 100
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 2.112492561340332,
      "learning_rate": 0.00019246861924686193,
      "loss": 2.025,
      "step": 110
    },
    {
      "epoch": 1.0622222222222222,
      "grad_norm": 1.6056971549987793,
      "learning_rate": 0.00018410041841004183,
      "loss": 1.9151,
      "step": 120
    },
    {
      "epoch": 1.1511111111111112,
      "grad_norm": 1.6668367385864258,
      "learning_rate": 0.00017573221757322176,
      "loss": 1.857,
      "step": 130
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.3783092498779297,
      "learning_rate": 0.00016736401673640169,
      "loss": 1.8314,
      "step": 140
    },
    {
      "epoch": 1.3288888888888888,
      "grad_norm": 1.805555820465088,
      "learning_rate": 0.00015899581589958158,
      "loss": 1.78,
      "step": 150
    },
    {
      "epoch": 1.4177777777777778,
      "grad_norm": 2.2435710430145264,
      "learning_rate": 0.0001506276150627615,
      "loss": 1.8114,
      "step": 160
    },
    {
      "epoch": 1.5066666666666668,
      "grad_norm": 1.3013173341751099,
      "learning_rate": 0.0001422594142259414,
      "loss": 1.7616,
      "step": 170
    },
    {
      "epoch": 1.5955555555555554,
      "grad_norm": 1.7825134992599487,
      "learning_rate": 0.00013389121338912134,
      "loss": 1.7355,
      "step": 180
    },
    {
      "epoch": 1.6844444444444444,
      "grad_norm": 1.720007300376892,
      "learning_rate": 0.00012552301255230126,
      "loss": 1.7954,
      "step": 190
    },
    {
      "epoch": 1.7733333333333334,
      "grad_norm": 2.054584503173828,
      "learning_rate": 0.00011715481171548118,
      "loss": 1.804,
      "step": 200
    },
    {
      "epoch": 1.7733333333333334,
      "eval_loss": 2.0029239654541016,
      "eval_runtime": 12.9891,
      "eval_samples_per_second": 7.699,
      "eval_steps_per_second": 3.849,
      "step": 200
    },
    {
      "epoch": 1.8622222222222222,
      "grad_norm": 1.596897006034851,
      "learning_rate": 0.00010878661087866109,
      "loss": 1.7857,
      "step": 210
    },
    {
      "epoch": 1.951111111111111,
      "grad_norm": 1.8957765102386475,
      "learning_rate": 0.000100418410041841,
      "loss": 1.6716,
      "step": 220
    },
    {
      "epoch": 2.0355555555555553,
      "grad_norm": 1.1805137395858765,
      "learning_rate": 9.205020920502092e-05,
      "loss": 1.6664,
      "step": 230
    },
    {
      "epoch": 2.1244444444444444,
      "grad_norm": 1.6200097799301147,
      "learning_rate": 8.368200836820084e-05,
      "loss": 1.4662,
      "step": 240
    },
    {
      "epoch": 2.2133333333333334,
      "grad_norm": 1.674241065979004,
      "learning_rate": 7.531380753138076e-05,
      "loss": 1.4722,
      "step": 250
    },
    {
      "epoch": 2.3022222222222224,
      "grad_norm": 1.8343427181243896,
      "learning_rate": 6.694560669456067e-05,
      "loss": 1.3892,
      "step": 260
    },
    {
      "epoch": 2.391111111111111,
      "grad_norm": 1.9408940076828003,
      "learning_rate": 5.857740585774059e-05,
      "loss": 1.4432,
      "step": 270
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.1669511795043945,
      "learning_rate": 5.02092050209205e-05,
      "loss": 1.445,
      "step": 280
    },
    {
      "epoch": 2.568888888888889,
      "grad_norm": 2.204439878463745,
      "learning_rate": 4.184100418410042e-05,
      "loss": 1.4398,
      "step": 290
    },
    {
      "epoch": 2.6577777777777776,
      "grad_norm": 2.812283754348755,
      "learning_rate": 3.3472803347280334e-05,
      "loss": 1.436,
      "step": 300
    },
    {
      "epoch": 2.6577777777777776,
      "eval_loss": 2.0947086811065674,
      "eval_runtime": 12.9562,
      "eval_samples_per_second": 7.718,
      "eval_steps_per_second": 3.859,
      "step": 300
    },
    {
      "epoch": 2.7466666666666666,
      "grad_norm": 1.698896884918213,
      "learning_rate": 2.510460251046025e-05,
      "loss": 1.4939,
      "step": 310
    },
    {
      "epoch": 2.8355555555555556,
      "grad_norm": 1.8192477226257324,
      "learning_rate": 1.6736401673640167e-05,
      "loss": 1.3922,
      "step": 320
    },
    {
      "epoch": 2.924444444444444,
      "grad_norm": 1.6893137693405151,
      "learning_rate": 8.368200836820084e-06,
      "loss": 1.3971,
      "step": 330
    }
  ],
  "logging_steps": 10,
  "max_steps": 339,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1806659598925824.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
